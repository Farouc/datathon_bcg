{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4e054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√©l√©chargement des donn√©es m√©t√©o...\n",
      "T√©l√©chargement des jours f√©ri√©s...\n",
      "T√©l√©chargement des vacances scolaires...\n",
      "T√©l√©chargement des √©v√©nements...\n",
      "‚ö†Ô∏è Erreur √©v√©nements : HTTP Error 500: Internal Server Error\n",
      "\n",
      "‚úÖ Donn√©es externes fusionn√©es sauvegard√©es dans : external_data\\external_features_paris.csv\n",
      "\n",
      "                 time        date  hour  temperature_2m  precipitation  \\\n",
      "0 2024-10-01 00:00:00  2024-10-01     0            14.0            0.0   \n",
      "1 2024-10-01 01:00:00  2024-10-01     1            13.8            0.0   \n",
      "2 2024-10-01 02:00:00  2024-10-01     2            13.7            0.0   \n",
      "3 2024-10-01 03:00:00  2024-10-01     3            13.5            0.0   \n",
      "4 2024-10-01 04:00:00  2024-10-01     4            12.6            0.0   \n",
      "\n",
      "   cloud_cover  wind_speed_10m  is_holiday  is_vacation  has_event  \n",
      "0          100            19.2         0.0        False          0  \n",
      "1          100            18.7         0.0        False          0  \n",
      "2          100            19.6         0.0        False          0  \n",
      "3          100            18.4         0.0        False          0  \n",
      "4          100            16.4         0.0        False          0  \n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# üå¶Ô∏è Donn√©es externes Paris (M√©t√©o + F√©ri√©s + Vacances + √âv√©nements)\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üìÅ Dossier de sortie\n",
    "# ------------------------------------------------------------\n",
    "output_dir = \"external_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Grille temporelle\n",
    "# ------------------------------------------------------------\n",
    "start = datetime(2024, 10, 1)\n",
    "end = datetime(2025, 11, 12, 23)\n",
    "hours = pd.date_range(start=start, end=end, freq=\"H\")\n",
    "features = pd.DataFrame({\"time\": hours})\n",
    "features[\"date\"] = features[\"time\"].dt.date\n",
    "features[\"hour\"] = features[\"time\"].dt.hour\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ M√©t√©o : d√©coupe archive + forecast\n",
    "# ------------------------------------------------------------\n",
    "print(\"T√©l√©chargement des donn√©es m√©t√©o...\")\n",
    "\n",
    "def fetch_meteo(base_url, start_date, end_date):\n",
    "    \"\"\"T√©l√©charge la m√©t√©o entre start_date et end_date\"\"\"\n",
    "    params = {\n",
    "        \"latitude\": 48.8566,\n",
    "        \"longitude\": 2.3522,\n",
    "        \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"hourly\": \"temperature_2m,precipitation,cloud_cover,wind_speed_10m\",\n",
    "        \"timezone\": \"Europe/Paris\"\n",
    "    }\n",
    "    r = requests.get(base_url, params=params)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if \"hourly\" not in data:\n",
    "        return pd.DataFrame()\n",
    "    meteo = pd.DataFrame(data[\"hourly\"])\n",
    "    meteo[\"time\"] = pd.to_datetime(meteo[\"time\"])\n",
    "    return meteo\n",
    "\n",
    "today = datetime.utcnow().date()\n",
    "try:\n",
    "    # 1Ô∏è‚É£ Archive (jusqu‚Äô√† aujourd‚Äôhui)\n",
    "    meteo_archive = fetch_meteo(\"https://archive-api.open-meteo.com/v1/archive\",\n",
    "                                datetime(2024, 10, 1),\n",
    "                                datetime(today.year, today.month, today.day))\n",
    "    # 2Ô∏è‚É£ Pr√©vision (de maintenant √† 12 novembre)\n",
    "    meteo_forecast = fetch_meteo(\"https://api.open-meteo.com/v1/forecast\",\n",
    "                                 datetime(today.year, today.month, today.day),\n",
    "                                 datetime(2025, 11, 12))\n",
    "\n",
    "    meteo = pd.concat([meteo_archive, meteo_forecast], ignore_index=True)\n",
    "    meteo.to_csv(os.path.join(output_dir, \"meteo_raw.csv\"), index=False)\n",
    "    features = features.merge(meteo, on=\"time\", how=\"left\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Erreur t√©l√©chargement m√©t√©o :\", e)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Jours f√©ri√©s\n",
    "# ------------------------------------------------------------\n",
    "print(\"T√©l√©chargement des jours f√©ri√©s...\")\n",
    "try:\n",
    "    feries = pd.read_csv(\"https://etalab.github.io/jours-feries-france-data/csv/jours_feries_metropole.csv\")\n",
    "    feries[\"date\"] = pd.to_datetime(feries[\"date\"]).dt.date\n",
    "    feries[\"is_holiday\"] = 1\n",
    "    features = features.merge(feries[[\"date\", \"is_holiday\"]], on=\"date\", how=\"left\").fillna({\"is_holiday\": 0})\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Erreur jours f√©ri√©s :\", e)\n",
    "    features[\"is_holiday\"] = 0\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Vacances scolaires (Zone C)\n",
    "# ------------------------------------------------------------\n",
    "print(\"T√©l√©chargement des vacances scolaires...\")\n",
    "try:\n",
    "    vac_url = \"https://data.education.gouv.fr/explore/dataset/fr-en-calendrier-scolaire/download/?format=csv\"\n",
    "    vac = pd.read_csv(vac_url, sep=\";\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    vac = vac[vac[\"zones\"].str.contains(\"Zone C\", na=False)]\n",
    "    start_col = \"date_debut\" if \"date_debut\" in vac.columns else \"start_date\"\n",
    "    end_col = \"date_fin\" if \"date_fin\" in vac.columns else \"end_date\"\n",
    "    vac[\"start_date\"] = pd.to_datetime(vac[start_col], errors=\"coerce\")\n",
    "    vac[\"end_date\"] = pd.to_datetime(vac[end_col], errors=\"coerce\")\n",
    "    vac = vac.dropna(subset=[\"start_date\", \"end_date\"])\n",
    "    vac.to_csv(os.path.join(output_dir, \"vacances_zoneC.csv\"), index=False)\n",
    "\n",
    "    def in_vacation(date):\n",
    "        return any((row.start_date.date() <= date <= row.end_date.date()) for row in vac.itertuples())\n",
    "\n",
    "    features[\"is_vacation\"] = features[\"date\"].apply(in_vacation)\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Erreur vacances scolaires :\", e)\n",
    "    features[\"is_vacation\"] = 0\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ √âv√©nements (optionnel, g√©r√© avec tol√©rance)\n",
    "# ------------------------------------------------------------\n",
    "print(\"T√©l√©chargement des √©v√©nements...\")\n",
    "try:\n",
    "    events_url = \"https://opendata.paris.fr/explore/dataset/que-faire-a-paris-/download/?format=csv\"\n",
    "    events = pd.read_csv(events_url, sep=\";\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    events[\"date_start\"] = pd.to_datetime(events[\"date_start\"], errors=\"coerce\")\n",
    "    events[\"date_end\"] = pd.to_datetime(events[\"date_end\"], errors=\"coerce\")\n",
    "    events = events.dropna(subset=[\"date_start\", \"date_end\"])\n",
    "\n",
    "    def has_event(date):\n",
    "        return any((row.date_start.date() <= date <= row.date_end.date()) for row in events.itertuples())\n",
    "\n",
    "    features[\"has_event\"] = features[\"date\"].apply(has_event)\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Erreur √©v√©nements :\", e)\n",
    "    features[\"has_event\"] = 0\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Export final\n",
    "# ------------------------------------------------------------\n",
    "output_path = os.path.join(output_dir, \"external_features_paris.csv\")\n",
    "features.to_csv(output_path, index=False)\n",
    "print(f\"\\n‚úÖ Donn√©es externes fusionn√©es sauvegard√©es dans : {output_path}\\n\")\n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5aac2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du fichier des √©v√©nements locaux...\n",
      "‚úÖ 971 lignes avec dates valides.\n",
      "‚úÖ 749 √©v√©nements conserv√©s entre 2024-10-01 et 2025-11-12\n",
      "‚úÖ Fichier nettoy√© sauvegard√© dans : external_data\\evenements_filtr√©s.csv\n",
      "\n",
      "Aper√ßu des premiers √©v√©nements :\n",
      "                                                Titre       Date de d√©but  \\\n",
      "0                Balade au c≈ìur des Passages Couverts 2024-01-10 01:00:00   \n",
      "8                                  La Cage aux Folles 2025-05-12 02:00:00   \n",
      "11               D√©couverte des petits jardins du 20e 2025-05-07 18:00:00   \n",
      "13            L'amour universel envahit le Lucernaire 2025-04-09 00:00:00   \n",
      "19           Pierre Bertrand et La Caja Negra Quartet 2025-03-12 21:00:00   \n",
      "20                         Thomas Galliano Organ Trio 2025-06-11 22:00:00   \n",
      "21             Conf√©rence sur les Catacombes de Paris 2025-05-11 21:00:00   \n",
      "26  #BrasilianJam La jam du dimanche de Isa√Øa Alve... 2025-02-11 21:30:00   \n",
      "29  Les gens de Paris, 1926-1936 ¬∑ Dans le miroir ... 2025-08-10 13:00:00   \n",
      "31                                      Th√©√¢tre forum 2025-06-11 21:00:00   \n",
      "\n",
      "           Date de fin                                        Nom du lieu  \\\n",
      "0  2029-01-01 00:59:59                                      Place Colette   \n",
      "8  2026-11-01 00:59:59                                Th√©√¢tre du Ch√¢telet   \n",
      "11 2025-08-11 18:30:00                                            jardins   \n",
      "13 2025-09-11 20:45:00                                      Le Lucernaire   \n",
      "19 2025-03-12 23:00:00                                 Le Son de la Terre   \n",
      "20 2025-06-12 00:00:00                                 Le Son de la Terre   \n",
      "21 2025-05-11 22:00:00  Biblioth√®que historique de la Ville de Paris (...   \n",
      "26 2025-03-11 00:00:00                                     Le Baiser Sal√©   \n",
      "29 2026-08-02 20:00:00               Mus√©e Carnavalet - Histoire de Paris   \n",
      "31 2026-05-02 22:30:00                       International Visual Theatre   \n",
      "\n",
      "                            Adresse du lieu Code postal     Ville  \\\n",
      "0                Devant la Com√©die-Fran√ßais       75001     Paris   \n",
      "8                       1 place du Ch√¢telet       75001     Paris   \n",
      "11  4 Pl. Saint-Blaise, 75020 Paris, France       75020     Paris   \n",
      "13            53, rue Notre-Dame des Champs       75006     Paris   \n",
      "19                     2 Port de Montebello       75005  Paris 05   \n",
      "20                     2 Port de Montebello       75005  Paris 05   \n",
      "21                             24 rue Pav√©e       75004     Paris   \n",
      "26                      58 Rue des Lombards       75001     Paris   \n",
      "29                23, rue Madame de S√©vign√©       75003     Paris   \n",
      "31                           7 Cit√© Chaptal       75009     Paris   \n",
      "\n",
      "   Type d'acc√®s            Type de prix  \\\n",
      "0   obligatoire                  payant   \n",
      "8   obligatoire                  payant   \n",
      "11  obligatoire                  payant   \n",
      "13  obligatoire                  payant   \n",
      "19  obligatoire                  payant   \n",
      "20  obligatoire                  payant   \n",
      "21  obligatoire                 gratuit   \n",
      "26          nan  gratuit sous condition   \n",
      "29  obligatoire                  payant   \n",
      "31  obligatoire                  payant   \n",
      "\n",
      "                                       D√©tail du prix Transport  \n",
      "0   <ul><li>Adulte : 14,50 ‚Ç¨</li><li>- 18 ans : 10...       nan  \n",
      "8                                <p>De 12 √† 129 ‚Ç¨</p>       nan  \n",
      "11                       <p>Tarif adulte : 16.5 ‚Ç¨</p>       nan  \n",
      "13                                <p>de 10‚Ç¨ √† 32‚Ç¨</p>       nan  \n",
      "19                               Billetterie : 25 EUR       nan  \n",
      "20                               Billetterie : 25 EUR       nan  \n",
      "21                                                nan       nan  \n",
      "26                                                nan       nan  \n",
      "29                           <p>De 13 √† 15 euros.</p>       nan  \n",
      "31  <p>Tarif : 12‚Ç¨ ou 10‚Ç¨, voir le d√©tail des tari...       nan  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Lecture du CSV local\n",
    "# ------------------------------------------------------------\n",
    "csv_path = \"./que_faire_a_paris.csv\"  # fichier t√©l√©charg√©\n",
    "output_dir = \"external_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Lecture du fichier des √©v√©nements locaux...\")\n",
    "\n",
    "# Lecture tol√©rante avec encodage fran√ßais\n",
    "events = pd.read_csv(\n",
    "    csv_path, sep=\";\", engine=\"python\", on_bad_lines=\"skip\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Conversion robuste des dates\n",
    "# ------------------------------------------------------------\n",
    "def safe_to_datetime(series):\n",
    "    \"\"\"Convertit une colonne en datetime, g√®re formats fran√ßais et fuseaux horaires.\"\"\"\n",
    "    s = pd.to_datetime(series, errors=\"coerce\", dayfirst=True, utc=True)\n",
    "    # Supprime le fuseau horaire (convertit en heure locale sans offset)\n",
    "    return s.dt.tz_convert(\"Europe/Paris\").dt.tz_localize(None)\n",
    "\n",
    "# Conversion forc√©e des deux colonnes principales\n",
    "for col in [\"Date de d√©but\", \"Date de fin\"]:\n",
    "    if col in events.columns:\n",
    "        events[col] = safe_to_datetime(events[col])\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Colonne manquante : {col}\")\n",
    "\n",
    "# Suppression des lignes sans dates valides\n",
    "events = events.dropna(subset=[\"Date de d√©but\", \"Date de fin\"])\n",
    "print(f\"‚úÖ {len(events)} lignes avec dates valides.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Filtrage temporel (2024-10-01 ‚Üí 2025-11-12)\n",
    "# ------------------------------------------------------------\n",
    "start = datetime(2024, 10, 1)\n",
    "end = datetime(2025, 11, 12)\n",
    "\n",
    "mask = (events[\"Date de fin\"] >= start) & (events[\"Date de d√©but\"] <= end)\n",
    "events = events.loc[mask].copy()\n",
    "\n",
    "print(f\"‚úÖ {len(events)} √©v√©nements conserv√©s entre {start.date()} et {end.date()}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ S√©lection des colonnes pertinentes\n",
    "# ------------------------------------------------------------\n",
    "cols_to_keep = [\n",
    "    \"Titre\",\n",
    "    \"Date de d√©but\",\n",
    "    \"Date de fin\",\n",
    "    \"Nom du lieu\",\n",
    "    \"Adresse du lieu\",\n",
    "    \"Code postal\",\n",
    "    \"Ville\",\n",
    "    \"Type d'acc√®s\",\n",
    "    \"Type de prix\",\n",
    "    \"D√©tail du prix\",\n",
    "    \"Transport\",\n",
    "]\n",
    "cols_to_keep = [c for c in cols_to_keep if c in events.columns]\n",
    "events = events[cols_to_keep]\n",
    "\n",
    "# Nettoyage basique des cha√Ænes\n",
    "for col in events.select_dtypes(include=\"object\").columns:\n",
    "    events[col] = events[col].astype(str).str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Sauvegarde du fichier nettoy√©\n",
    "# ------------------------------------------------------------\n",
    "output_path = os.path.join(output_dir, \"evenements_filtr√©s.csv\")\n",
    "events.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Fichier nettoy√© sauvegard√© dans : {output_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ (Optionnel) V√©rification\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nAper√ßu des premiers √©v√©nements :\")\n",
    "print(events.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "447fe7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z\\AppData\\Local\\Temp\\ipykernel_53640\\2143330003.py:40: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = events[\"Adresse du lieu\"].fillna(\"\").str.contains(keyword, case=False, regex=True) | \\\n",
      "C:\\Users\\Z\\AppData\\Local\\Temp\\ipykernel_53640\\2143330003.py:41: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  events[\"Code postal\"].fillna(\"\").astype(str).str.contains(keyword)\n",
      "C:\\Users\\Z\\AppData\\Local\\Temp\\ipykernel_53640\\2143330003.py:40: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = events[\"Adresse du lieu\"].fillna(\"\").str.contains(keyword, case=False, regex=True) | \\\n",
      "C:\\Users\\Z\\AppData\\Local\\Temp\\ipykernel_53640\\2143330003.py:41: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  events[\"Code postal\"].fillna(\"\").astype(str).str.contains(keyword)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier d'√©v√©nements temporels sauvegard√© : external_data/events_features.csv\n",
      "\n",
      "Aper√ßu :\n",
      "        date  has_event  has_event_champs  has_event_stsperes  \\\n",
      "0 2024-10-01          1                 0                   1   \n",
      "1 2024-10-02          1                 0                   1   \n",
      "2 2024-10-03          1                 0                   1   \n",
      "3 2024-10-04          1                 0                   1   \n",
      "4 2024-10-05          1                 0                   1   \n",
      "5 2024-10-06          1                 0                   1   \n",
      "6 2024-10-07          1                 0                   1   \n",
      "7 2024-10-08          1                 0                   1   \n",
      "8 2024-10-09          1                 0                   1   \n",
      "9 2024-10-10          1                 0                   1   \n",
      "\n",
      "   has_event_convention  \n",
      "0                     1  \n",
      "1                     1  \n",
      "2                     1  \n",
      "3                     1  \n",
      "4                     1  \n",
      "5                     1  \n",
      "6                     1  \n",
      "7                     1  \n",
      "8                     1  \n",
      "9                     1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Lecture du fichier d'√©v√©nements nettoy√©\n",
    "# ------------------------------------------------------------\n",
    "events_path = \"external_data/evenements_filtr√©s.csv\"\n",
    "events = pd.read_csv(events_path, encoding=\"utf-8\")\n",
    "\n",
    "# Conversion en datetime\n",
    "events[\"Date de d√©but\"] = pd.to_datetime(events[\"Date de d√©but\"], errors=\"coerce\")\n",
    "events[\"Date de fin\"] = pd.to_datetime(events[\"Date de fin\"], errors=\"coerce\")\n",
    "events = events.dropna(subset=[\"Date de d√©but\", \"Date de fin\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Cr√©ation de la plage temporelle d‚Äôint√©r√™t\n",
    "# ------------------------------------------------------------\n",
    "start = datetime(2024, 10, 1)\n",
    "end = datetime(2025, 11, 12)\n",
    "dates = pd.date_range(start=start, end=end, freq=\"D\")\n",
    "features = pd.DataFrame({\"date\": dates})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Fonction pour savoir si un √©v√©nement est actif un jour donn√©\n",
    "# ------------------------------------------------------------\n",
    "def has_event(date, subset=None):\n",
    "    df = events if subset is None else subset\n",
    "    return ((df[\"Date de d√©but\"] <= date) & (df[\"Date de fin\"] >= date)).any()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Indicateur global\n",
    "# ------------------------------------------------------------\n",
    "features[\"has_event\"] = features[\"date\"].apply(has_event)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Indicateurs locaux (par zone)\n",
    "# ------------------------------------------------------------\n",
    "def filter_zone(keyword):\n",
    "    mask = events[\"Adresse du lieu\"].fillna(\"\").str.contains(keyword, case=False, regex=True) | \\\n",
    "           events[\"Code postal\"].fillna(\"\").astype(str).str.contains(keyword)\n",
    "    return events[mask].copy()\n",
    "\n",
    "zones = {\n",
    "    \"champs\": r\"elys(√©es)?|75008\",\n",
    "    \"stsperes\": r\"saints?-p(√®|e)res|75006\",\n",
    "    \"convention\": r\"convention|75015\",\n",
    "}\n",
    "\n",
    "for zone_name, pattern in zones.items():\n",
    "    subset = filter_zone(pattern)\n",
    "    features[f\"has_event_{zone_name}\"] = features[\"date\"].apply(lambda d: has_event(d, subset))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Conversion en 0/1 et sauvegarde\n",
    "# ------------------------------------------------------------\n",
    "for c in features.columns:\n",
    "    if c != \"date\":\n",
    "        features[c] = features[c].astype(int)\n",
    "\n",
    "output_path = \"external_data/events_features.csv\"\n",
    "features.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Fichier d'√©v√©nements temporels sauvegard√© : {output_path}\")\n",
    "\n",
    "print(\"\\nAper√ßu :\")\n",
    "print(features.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e6b3d",
   "metadata": {},
   "source": [
    "Fusion finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c055fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es finales fusionn√©es sauvegard√©es dans : external_data/external_features_final.csv\n",
      "                  time       date  hour  temperature_2m  precipitation  \\\n",
      "0  2024-10-01 00:00:00 2024-10-01     0            14.0            0.0   \n",
      "1  2024-10-01 01:00:00 2024-10-01     1            13.8            0.0   \n",
      "2  2024-10-01 02:00:00 2024-10-01     2            13.7            0.0   \n",
      "3  2024-10-01 03:00:00 2024-10-01     3            13.5            0.0   \n",
      "4  2024-10-01 04:00:00 2024-10-01     4            12.6            0.0   \n",
      "5  2024-10-01 05:00:00 2024-10-01     5            12.1            0.0   \n",
      "6  2024-10-01 06:00:00 2024-10-01     6            11.8            0.0   \n",
      "7  2024-10-01 07:00:00 2024-10-01     7            11.5            0.0   \n",
      "8  2024-10-01 08:00:00 2024-10-01     8            12.0            0.0   \n",
      "9  2024-10-01 09:00:00 2024-10-01     9            13.1            0.0   \n",
      "\n",
      "   cloud_cover  wind_speed_10m  is_holiday  is_vacation  has_event  \\\n",
      "0          100            19.2         0.0        False          0   \n",
      "1          100            18.7         0.0        False          0   \n",
      "2          100            19.6         0.0        False          0   \n",
      "3          100            18.4         0.0        False          0   \n",
      "4          100            16.4         0.0        False          0   \n",
      "5          100            14.9         0.0        False          0   \n",
      "6          100            14.4         0.0        False          0   \n",
      "7          100            14.3         0.0        False          0   \n",
      "8          100            14.0         0.0        False          0   \n",
      "9          100            14.9         0.0        False          0   \n",
      "\n",
      "   has_event_champs  has_event_stsperes  has_event_convention  \n",
      "0                 0                   1                     1  \n",
      "1                 0                   1                     1  \n",
      "2                 0                   1                     1  \n",
      "3                 0                   1                     1  \n",
      "4                 0                   1                     1  \n",
      "5                 0                   1                     1  \n",
      "6                 0                   1                     1  \n",
      "7                 0                   1                     1  \n",
      "8                 0                   1                     1  \n",
      "9                 0                   1                     1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Chargement des deux fichiers\n",
    "# ------------------------------------------------------------\n",
    "external = pd.read_csv(\"external_data/external_features_paris.csv\", parse_dates=[\"date\"])\n",
    "events = pd.read_csv(\"external_data/events_features.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Fusion sur la colonne 'date'\n",
    "# ------------------------------------------------------------\n",
    "merged = external.merge(\n",
    "    events,\n",
    "    on=\"date\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_event\")  # √©vite les doublons si 'has_event' existe d√©j√†\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Nettoyage : suppression du doublon global 'has_event'\n",
    "# ------------------------------------------------------------\n",
    "if \"has_event_event\" in merged.columns:\n",
    "    merged.drop(columns=[\"has_event_event\"], inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Valeurs manquantes ‚Üí 0 pour les indicateurs binaires\n",
    "# ------------------------------------------------------------\n",
    "for col in [\"has_event_champs\", \"has_event_stsperes\", \"has_event_convention\"]:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged[col].fillna(0).astype(int)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Sauvegarde finale\n",
    "# ------------------------------------------------------------\n",
    "output_path = \"external_data/external_features_final.csv\"\n",
    "merged.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Donn√©es finales fusionn√©es sauvegard√©es dans : {output_path}\")\n",
    "print(merged.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494d2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
